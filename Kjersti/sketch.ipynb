{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30cea9f9",
   "metadata": {},
   "source": [
    "# Project 1 FYS-STK4155\n",
    "### Trial run Kjersti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bbfd11b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8493b075",
   "metadata": {},
   "source": [
    "#### Part a) OLS for the Runge function\n",
    "\n",
    "* OLS regression analysis using polynomials in x up to order 15 or higher. Add stochastic noise.\n",
    "* Explore the dependence on the number of data points and the polynomial degree\n",
    "* Evalute the MSE and R^2 scores. Plot them as functions of polynomial degree.\n",
    "* Plot the parameters $\\theta$ as you increase the order of the polynomial. Comment the results.\n",
    "* You have to include a scaling/centering of the data.\n",
    "* Present a critical discussion of why and how you have scaled the data.\n",
    "* You have to split into test and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fb9d33a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vals = np.arange(10, 1500, 100)  # number of data points\n",
    "p_vals = np.arange(2, 16) # polynomial degree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7089dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(n):\n",
    "    '''\n",
    "    Make a dataset with a given number (n) datapoints\n",
    "    of the Runge function.\n",
    "    '''\n",
    "    x = np.linspace(-1, 1, n)\n",
    "    y = 1/(1 + 25*x**2) + np.random.normal(0, 0.1)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def polynomial_features(x, p):\n",
    "    '''\n",
    "    Make a design matrix.\n",
    "    '''\n",
    "    n = len(x)\n",
    "    X = np.zeros((n, p + 1))\n",
    "    X[:, 0] = 1\n",
    "    for i in range(1, p+1):\n",
    "        X[:, i] = x**i\n",
    "\n",
    "    return X\n",
    "\n",
    "def OLS_parameters(X, y):\n",
    "    ''' \n",
    "    Find the OLS parameters\n",
    "    '''\n",
    "    X_T = np.transpose(X)\n",
    "    X_T_X = X_T @ X\n",
    "\n",
    "    return np.linalg.pinv(X_T_X) @ X_T @ y\n",
    "\n",
    "def MSE(y_data, y_pred):\n",
    "    ''' \n",
    "    Mean square error\n",
    "    '''\n",
    "    return np.mean((y_data - y_pred)**2)\n",
    "\n",
    "def R2(y_data, y_pred):\n",
    "    return 1 - (np.sum((y_data - y_pred)**2))/(np.sum((y_data - np.mean(y_data))**2))\n",
    "\n",
    "def standardize(X, y):\n",
    "    # Standardize features (zero mean, unit variance for each feature)\n",
    "    X_mean = X.mean(axis=0) # The mean of each column/feature\n",
    "    X_std = X.std(axis=0)\n",
    "    X_std[X_std == 0] = 1  # safeguard to avoid division by zero for constant features\n",
    "    X_norm = (X - X_mean) / X_std\n",
    "\n",
    "    # Center the target to zero mean (optional, to simplify intercept handling)\n",
    "    y_mean = y.mean()\n",
    "    y_centered = y - y_mean\n",
    "\n",
    "    return X_norm, y_centered\n",
    "\n",
    "def split_n_train(X, y, size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6a41f268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/bn0hk5sx7fq7r171hlv9tzq40000gn/T/ipykernel_86225/942559193.py:39: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 1 - (np.sum((y_data - y_pred)**2))/(np.sum((y_data - np.mean(y_data))**2))\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for n in n_vals:\n",
    "    x, y = make_data(n)\n",
    "\n",
    "    for p in p_vals:\n",
    "        X = polynomial_features(x, p)\n",
    "        X, y = standardize(X, y)\n",
    "        X_train, X_test, y_train, y_test = split_n_train(X, y, size=0.2)\n",
    "\n",
    "        theta = OLS_parameters(X_train, y_train)\n",
    "        y_pred = X_test @ theta\n",
    "\n",
    "        results.append({\"n\": n, \"p\": p, \"theta\": theta, \"MSE\": MSE(y_test, y_pred), \"R2\": R2(y_test, y_pred)})\n",
    "\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6d67e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
